name: Collect all CFB data (UPA-F)

on:
  workflow_dispatch:
    inputs:
      year:
        description: "Season year to collect (defaults to 2025)"
        required: false
        type: string
  schedule:
    # Twice daily (UTC) â€” adjust as needed
    - cron: "15 5,17 * * *"

permissions:
  contents: write

concurrency:
  group: collect-all
  cancel-in-progress: false

env:
  PYTHONUNBUFFERED: "1"
  TZ: America/Phoenix
  # Optional: set to "1" to allow HTTP fallback if SDK returns 0 schedule rows
  UPA_ALLOW_HTTP_FALLBACK: "0"

jobs:
  collect:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          if [ -f agents/requirements.txt ]; then
            pip install -r agents/requirements.txt
          fi
          # Ensure these are present even if requirements.txt is minimal
          pip install cfbd pandas requests google-auth google-auth-oauthlib gspread

      - name: Run collector
        env:
          # REQUIRED
          BEARER_TOKEN: ${{ secrets.BEARER_TOKEN }}
          # OPTIONAL (leave unset if not using Sheets)
          SHEET_ID: ${{ secrets.SHEET_ID }}
          # Year: use dispatch input if provided, otherwise 2025
          UPA_YEAR: ${{ github.event.inputs.year || '2025' }}
          UPA_ALLOW_HTTP_FALLBACK: ${{ env.UPA_ALLOW_HTTP_FALLBACK }}
        run: |
          set -e
          python agents/collect_cfbd_all.py

      - name: Debug artifacts
        run: |
          echo "== data directory =="
          ls -l data || true
          echo "== head: cfb_schedule.csv =="
          sed -n '1,20p' data/cfb_schedule.csv || true
          echo "== head: upa_team_inputs_datadriven_v0.csv =="
          sed -n '1,10p' data/upa_team_inputs_datadriven_v0.csv || true
          echo "== head: upa_predictions.csv =="
          sed -n '1,20p' data/upa_predictions.csv || true
          echo "== head: live_edge_report.csv =="
          sed -n '1,20p' data/live_edge_report.csv || true
          echo "== status.json =="
          cat data/status.json || true

      - name: Upload data as workflow artifact (for quick download)
        uses: actions/upload-artifact@v4
        with:
          name: upa-f-data
          path: |
            data/*.csv
            data/status.json
          if-no-files-found: warn
          retention-days: 7

      - name: Commit & push data (auto-rebase)
        run: |
          set -e
          git config user.name  "github-actions"
          git config user.email "actions@github.com"

          # Stage only generated data files
          git add data/*.csv data/status.json || true

          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "data: update (${{ github.event.inputs.year || '2025' }})"

          # Rebase on latest main to avoid non-fast-forward errors
          git fetch origin main
          git pull --rebase origin main || true

          git push origin HEAD:main