name: deploy

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      purge_caches:
        description: 'Delete cached API data before run (true/false)'
        required: false
        default: 'false'
      enable_cache:
        description: 'Use cached API data (true/false)'
        required: false
        default: 'false'
      enable_backtest:
        description: 'Run collector backtest pass (true/false)'
        required: false
        default: 'false'
      backtest_year:
        description: 'Backtest season to run when enabled'
        required: false
        default: '2024'

permissions:
  contents: write
  pages: write
  id-token: write

env:
  MARKET_SOURCE: fanduel
  ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}
  ODDS_CACHE_DIR: .cache_odds/2025
  ODDS_CACHE_TTL_DAYS: 2
  FANDUEL_CACHE_ONLY: '1'
  # Ensure Actions cache paths match code defaults
  CACHE_DIR: .cache_cfbd/2025
  UPA_LOG_LEVEL: DEBUG
  UPA_AUTO_GIT_ADD: 0
  CACHE_VERSION: v6
  CACHE_ENABLED: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.enable_cache == 'true' && 'true' || 'false' }}
  BACKTEST_ENABLED: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.enable_backtest == 'true' && 'true' || 'false' }}
  BACKTEST_YEAR: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backtest_year || '2024' }}
  DATA_DB_PATH: data/upa_data.sqlite
  CACHE_DB_PATH: data/upa_cache.sqlite

# Serialize with other Pages publishers to avoid races
concurrency:
  group: pages
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Verify cache path configuration (fail only on mismatch)
        run: |
          set -euo pipefail
          CFBD_ENV_DIR="${CACHE_DIR:-.cache_cfbd/2025}"
          ODDS_ENV_DIR="${ODDS_CACHE_DIR:-.cache_odds/2025}"
          CFBD_EXPECT=".cache_cfbd/2025"
          ODDS_EXPECT=".cache_odds/2025"
          echo "CFBD cache (env): ${CFBD_ENV_DIR}  | expected workflow path: ${CFBD_EXPECT}"
          echo "ODDS cache (env): ${ODDS_ENV_DIR}  | expected workflow path: ${ODDS_EXPECT}"
          if [ "${CFBD_ENV_DIR}" != "${CFBD_EXPECT}" ] || [ "${ODDS_ENV_DIR}" != "${ODDS_EXPECT}" ]; then
            echo "::error::Cache path mismatch detected. Update either the workflow cache paths or the env values (CACHE_DIR/ODDS_CACHE_DIR) to match."
            echo "Details: CFBD_ENV_DIR='${CFBD_ENV_DIR}' vs EXPECT='${CFBD_EXPECT}', ODDS_ENV_DIR='${ODDS_ENV_DIR}' vs EXPECT='${ODDS_EXPECT}'"
            exit 1
          fi
          echo "Cache paths are consistent."

      - name: Purge caches (optional)
        if: ${{ env.CACHE_ENABLED == 'true' && github.event_name == 'workflow_dispatch' && github.event.inputs.purge_caches == 'true' }}
        run: |
          set -euo pipefail
          rm -rf .cache_cfbd/2025 .cache_odds/2025
          echo "Caches purged per workflow_dispatch input."

      - name: Restore API caches (CFBD & Odds)
        if: ${{ env.CACHE_ENABLED == 'true' }}
        uses: actions/cache@v4
        with:
          path: |
            .cache_cfbd/2025
            .cache_odds/2025
          key: api-caches-${{ runner.os }}-${{ env.MARKET_SOURCE }}-season-2025-${{ env.CACHE_VERSION }}-${{ hashFiles('agents/collect_cfbd_all.py') }}
          restore-keys: |
            api-caches-${{ runner.os }}-${{ env.MARKET_SOURCE }}-season-2025-${{ env.CACHE_VERSION }}-
            api-caches-${{ runner.os }}-${{ env.MARKET_SOURCE }}-season-2025-
            api-caches-${{ runner.os }}-${{ env.MARKET_SOURCE }}-
            api-caches-${{ runner.os }}-

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install -r agents/requirements.txt

      - name: Check CFBD token (warning only)
        run: |
          if [ -z "${{ secrets.CFBD_BEARER_TOKEN }}" ]; then
            echo "::warning::CFBD_BEARER_TOKEN secret is empty. Without it, schedule may be tiny and FanDuel mapping will be skipped."
          else
            echo "CFBD_BEARER_TOKEN is present."
          fi

      - name: Run collector (live + optional backtest)
        env:
          CFBD_BEARER_TOKEN: ${{ secrets.CFBD_BEARER_TOKEN }}
          BEARER_TOKEN: ${{ secrets.CFBD_BEARER_TOKEN }}
          MARKET_SOURCE: ${{ env.MARKET_SOURCE }}
          ODDS_API_KEY: ${{ env.ODDS_API_KEY }}
          ODDS_CACHE_DIR: ${{ env.ODDS_CACHE_DIR }}
          ODDS_CACHE_TTL_DAYS: ${{ env.ODDS_CACHE_TTL_DAYS }}
          CACHE_DIR: ${{ env.CACHE_DIR }}
          DEBUG_MARKET: 1
          REQUIRE_SCHED_MIN_ROWS: 0
          MARKET_MIN_ROWS: 1
        run: |
          # Run main collector; market_debug.json will be emitted by the script when available
          BACKTEST_ARGS=""
          if [ "${BACKTEST_ENABLED}" = "true" ]; then
            echo "Backtest enabled for season ${BACKTEST_YEAR}"
            BACKTEST_ARGS="--backtest ${BACKTEST_YEAR}"
          else
            echo "Backtest disabled for this run."
          fi
          echo "MARKET_SOURCE (requested): ${MARKET_SOURCE}"
          python -m agents.collect_cfbd_all --market-source "${MARKET_SOURCE}" --year 2025 ${BACKTEST_ARGS}
          DB_PATH="${DATA_DB_PATH:-data/upa_data.sqlite}"
          if [ -f "$DB_PATH" ]; then
            echo "Collector finished; data stored in $DB_PATH"
          else
            echo "::warning::SQLite data file $DB_PATH not found"
          fi

      # Build every artifact needed for the site (always regenerate)
      - name: Build ALL site data (initial)
        env:
          CFBD_BEARER_TOKEN: ${{ secrets.CFBD_BEARER_TOKEN }}
          MARKET_SOURCE: ${{ env.MARKET_SOURCE }}
          ODDS_API_KEY: ${{ env.ODDS_API_KEY }}
          CACHE_DIR: ${{ env.CACHE_DIR }}
        run: |
          set -euo pipefail
          python -m tools.build_site_data --year 2025

      # Hard validation: fail build if core artifacts are empty or stale
      - name: Validate data completeness (initial)
        run: |
          set -euo pipefail
          python -m tools.validate_site_data --year 2025

      - name: Train residual model
        env:
          CFBD_BEARER_TOKEN: ${{ secrets.CFBD_BEARER_TOKEN }}
        run: |
          python -m agents.jobs.train_spread_model

      - name: Build ALL site data (post-train)
        env:
          CFBD_BEARER_TOKEN: ${{ secrets.CFBD_BEARER_TOKEN }}
          MARKET_SOURCE: ${{ env.MARKET_SOURCE }}
          ODDS_API_KEY: ${{ env.ODDS_API_KEY }}
          CACHE_DIR: ${{ env.CACHE_DIR }}
        run: |
          set -euo pipefail
          python -m tools.build_site_data --year 2025

      - name: Recompute backtest (offline)
        env:
          CFBD_BEARER_TOKEN: ${{ secrets.CFBD_BEARER_TOKEN }}
          BACKTEST_YEAR: ${{ env.BACKTEST_YEAR }}
        run: |
          set -euo pipefail
          python -m tools.build_backtest_data --year "${BACKTEST_YEAR}" --offline

      - name: Validate data completeness (post-train)
        run: |
          set -euo pipefail
          python -m tools.validate_site_data --year 2025

      - name: Run Python unit tests
        run: python -m pytest --maxfail=1 --disable-warnings

      - name: Install deps
        run: |
          if [ -f package-lock.json ]; then
            npm ci
          else
            npm i
          fi

      - name: Build UI
        run: npm run build

      - name: Copy data into dist
        run: |
          mkdir -p dist/data
          if [ -d data ]; then
            cp -R data/* dist/data/ || true
          fi
          if [ -d public ]; then
            cp -R public/* dist/ || true
          fi

      - name: Stage generated data artifacts
        run: |
          set -euo pipefail
          if [ -d data ]; then
            git add data/
          fi
          if [ -d dist ]; then
            git add dist/
          fi
          git status --short

      - name: Rebase onto origin/main (autostash)
        run: |
          set -euo pipefail
          git fetch origin main
          git pull --rebase --autostash origin main

      - name: Commit and push generated artifacts
        run: |
          set -euo pipefail
          if git diff --cached --quiet; then
            echo "No generated changes to commit."
          else
            git config user.name "GitHub Actions"
            git config user.email "actions@github.com"
            git commit -m "chore: update generated data [skip ci]"
            git push
          fi

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: dist

      - name: Upload portable site bundle (for live workflow)
        uses: actions/upload-artifact@v4
        with:
          name: site-bundle
          path: dist
          retention-days: 3

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - id: deployment
        uses: actions/deploy-pages@v4
